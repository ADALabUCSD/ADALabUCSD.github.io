# jemdoc: menu{MENU2}{vista.html}
= ADA Lab @ UCSD

~~~
{}{img_left}{images/vista.jpg}{}{}{80px}{}
== Project Vista
~~~ 

=== Overview

Deep convolutional neural networks (CNNs) have revolutionized computer vision,
achieving near-human accuracy on many prediction tasks. 
This has led to a growing interest in using deep CNNs to exploit images, video, 
and other unstructured data sources for analytics in many applications.
However, there are still numerous practical bottlenecks in using deep CNNs for 
data analytics, including for transfer learning with deep CNNs and interpeting 
such models in new analytics contexts.

In this project, we build a new data system to enable seamless and efficient 
exploitation of deep CNNs for emerging multimodal analytics workloads.
Rather than segregating multimedia data away in siloed systems, Vista will 
enable popular and scalable data analytics systems to truly /see/ such forms 
of data.

Vista currently supports large-scale transfer learning from deep CNNs for 
reliable, efficient, and easy-to-use multimodal analytics at scale in the Spark-TensorFlow 
environment. Please see the paper below for more details. 

=== Downloads (Paper, Code, Data, etc.)

- Vista: Optimized System for Declarative Feature Transfer from Deep CNNs at Scale\n
Supun Nakandala and Arun Kumar\n
ACM SIGMOD 2020 (To appear) | [papers/2020_Vista_SIGMOD.pdf Paper PDF] |
[papers/TR_2020_Vista.pdf TechReport] | [vista.html Code and Data]

- Materialization Trade-offs for Feature Transfer from Deep CNNs for Multimodal Data Analytics\n
Supun Nakandala and Arun Kumar\n
SysML 2018 Short paper/poster | [papers/2018_Vista_SysML.pdf Paper PDF]

=== Student Contact

Supun Nakandala: snakanda \[at\] eng \[dot\] ucsd \[dot\] edu

=== Acknowledgments

This project was\/is supported in part by a Hellman Fellowship.
